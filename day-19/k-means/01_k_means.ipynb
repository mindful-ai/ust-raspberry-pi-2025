{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps for k-means clustering are: \n",
    "Choose the number of clusters: Decide how many clusters to create, or the value of k. This can be done randomly or using a method like Elbow or Silhouette. \n",
    "Assign centroids: Randomly select k points from the dataset to be the initial centroids for each cluster. \n",
    "Calculate distances: Calculate the distance between each data point and each centroid. \n",
    "Assign observations: Assign each data point to the closest centroid. \n",
    "Update centroids: Find the new location of each centroid by taking the mean of all the observations in that cluster. \n",
    "Repeat: Repeat steps 3–5 until the centroids no longer change position. \n",
    "\n",
    "\n",
    "The output of k-means cluster analysis includes:\n",
    "A table of the mean values of each cluster on the clustering variables\n",
    "Which object has been classified into which cluster\n",
    "Plots and diagnostics to assess variation within and between clusters \n",
    "\n",
    "\n",
    "K-means clustering is used in a variety of applications, including document classification, image segmentation, and recommendation engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data and looking at the first five rows of the data\n",
    "data=pd.read_csv(r\"whole_sale_customers_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Region'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics of the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# statistics of scaled data\n",
    "pd.DataFrame(data_scaled).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the kmeans function with initialization as k-means++\n",
    "kmeans = KMeans(n_clusters=2, init='k-means++')\n",
    "\n",
    "# fitting the k means algorithm on scaled data\n",
    "kmeans.fit(data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the k-means clustering algorithm, inertia is a metric that measures how well a dataset has been clustered. It's calculated by measuring the distance between each data point and its centroid, squaring the distance, and summing those squares for each data point in the cluster. \n",
    "A lower inertia value indicates that the data points within the cluster are more compact or similar, and that the clusters are well-formed. A higher inertia value indicates that the data points are spread out and far from their centroids, and that the clustering is less optimal. \n",
    "The k-means algorithm aims to choose centroids that minimize inertia. A good model has low inertia and a low number of clusters (K), but there is a tradeoff because as K increases, inertia decreases. To find the optimal K for a dataset, you can use the Elbow method, which identifies the point where the decrease in inertia begins to slow. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inertia on the fitted data\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an inertia value of almost 2600. Now, let’s see how we can use the elbow curve to determine the optimum number of clusters in Python.\n",
    "\n",
    "We will first fit multiple k-means models and in each successive model, we will increase the number of clusters. We will store the inertia value of each model and then plot it to visualize the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting multiple k-means algorithms and storing the values in an empty list\n",
    "SSE = []\n",
    "for cluster in range(1,20):\n",
    "    kmeans = KMeans(n_clusters=cluster, init='k-means++')\n",
    "    kmeans.fit(data_scaled)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "# converting the results into a dataframe and plotting them\n",
    "frame = pd.DataFrame({'Cluster':range(1,20), 'SSE':SSE})\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(frame['Cluster'], frame['SSE'], marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k means using 5 clusters and k-means++ initialization\n",
    "kmeans = KMeans(n_clusters = 7, init='k-means++')\n",
    "kmeans.fit(data_scaled)\n",
    "pred = kmeans.predict(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(data_scaled)\n",
    "frame['cluster'] = pred\n",
    "frame['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are 234 data points belonging to cluster 4 (index 3), then 125 points in cluster 2 (index 1), and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhoutte Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the optimal number of clusters, you can calculate the silhouette score for different values of k and choose the one with the highest average silhouette score. You can also visualize the silhouette analysis using a silhouette plot, which can help identify clusters with low silhouette scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(data_scaled, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means for Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = r\"ladybug.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "image = imread(img)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = image.reshape(-1, 3)\n",
    "kmeans = KMeans(n_clusters=8, random_state=42).fit(X)\n",
    "segmented_img = kmeans.cluster_centers_\n",
    "len(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
    "segmented_img = segmented_img.reshape(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_imgs = []\n",
    "n_colors = (10, 8, 6, 4, 2)\n",
    "for n_clusters in n_colors:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)\n",
    "    segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
    "    segmented_imgs.append(segmented_img.reshape(image.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.1)\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original image\")\n",
    "plt.axis('off')\n",
    "\n",
    "for idx, n_clusters in enumerate(n_colors):\n",
    "    plt.subplot(232 + idx)\n",
    "    plt.imshow(segmented_imgs[idx])\n",
    "    plt.title(\"{} colors\".format(n_clusters))\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can experiment\n",
    "with various numbers of clusters, as shown in the figure. When you use less than 8\n",
    "clusters, notice that the ladybug’s flashy red color fails to get a cluster of its own: it\n",
    "gets merged with colors from the environment. This is due to the fact that the lady‐\n",
    "bug is quite small, much smaller than the rest of the image, so even though its color is\n",
    "flashy, K-Means fails to dedicate a cluster to it: as mentioned earlier, K-Means prefers\n",
    "clusters of similar sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Clustering for Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits, y_digits = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_score = log_reg.score(X_test, y_test)\n",
    "log_reg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's our baseline: 96.89% accuracy. Let's see if we can do better by using K-Means as a preprocessing step. We will create a pipeline that will first cluster the training set into 50 clusters and replace the images with their distances to the 50 clusters, then apply a logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"kmeans\", KMeans(n_clusters=50, random_state=42)),\n",
    "    (\"log_reg\", LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_score = pipeline.score(X_test, y_test)\n",
    "pipeline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
